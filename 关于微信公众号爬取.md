## 爬取
如何关闭证书校验：
```python
requests.packages.urllib3.disable_warnings()#不接收警告(因为会很吵)
response =  requests.get(url,headers = headers,verify=False) #关闭校验
```
### 网址
采用requests库进行爬取，不对head进行伪装，不进行证书校验
获得目标网页源码后进行进一步分析结构来获取内容
### 公众号
公众号采用微信公众号平台文章引用漏洞获取
目前需要手动进行公众号fakeid获取（因为吧……他有重名现象，很难受），我用fiddler抓包抓的URL
同样用requests库爬取，但是对head进行伪装（主要包括user-agent和cookie这两项），不进行证书校验

<font color="E62817">注意！url里的token每天（或许是每次登陆）都会变！！！！！</font>
#### 公众号URL结构分析
目前，对任意公众号内容获取url需要用到的结构分析如下：

1. 服务器头与请求类型（https://mp.weixin.qq.com/cgi-bin/appmsg?action=list_ex）
2. 标识公众号的fakeid（&fakeid=巴拉巴拉巴拉）
3. 从第几条开始（&query=&begin=数字）
4. 其他的配置项和token之类的（很遗憾的是count最大是10，最多一次请求十条，但通常够用了）（&count=4&type=9&need_author_name=1&token=1264466491&lang=zh_CN&f=json&ajax=1）
#### 页面结构分析
页面内容比较冗杂，按照python数据结构解析如下：
1. 字典：
	1. 没有弔用的标识码
	2. 内容（key：”app_msg_list“，列表）
		1. 单个文章信息，字典
			1. 各种没有弔用的id
			2. 文章封面（key：“cover”，URL）
			3. 文章标题（key：“title”，string）
			4. 文章作者（key：“author_name”，string）<font color="FA8C15">啊…这个要看文章有没有</font>
			5. 文章摘要（key：“digest”，string）<font color="FA8C15">啊…这个也要看文章有没有</font>
			6. 文章地址（key：“link”，URL）
			7. 文章创建时间（key：“create_time”，10位时间戳）
			8. 文章上传时间（key：“update_time”，10位时间戳）
	3. 不报错就没有弔用的返回码